{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181a9fc5",
   "metadata": {},
   "source": [
    "# Турнир «Камень-Ножницы-Бумага» с использованием 13 агентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457836ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /var/folders/n5/twq2syy550527g4q5jk2rg7h0000gn/T/matplotlib-0bmpwawf because the default path (/Users/pavelminsky/.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n",
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kaggle_environments import make\n",
    "import random\n",
    "import pandas as pd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b33e49",
   "metadata": {},
   "source": [
    "## Определение агентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ca9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Базовые агенты\n",
    "def rock_agent(observation, configuration):\n",
    "    return 0\n",
    "\n",
    "def copy_opponent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "def random_agent(observation, configuration):\n",
    "    return random.randrange(0, configuration.signs)\n",
    "\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1\n",
    "\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2\n",
    "\n",
    "def smart_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c4260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cycle_agent(observation, configuration):\n",
    "    \"\"\"Агент чередует ходы по циклу: Камень → Бумага → Ножницы\"\"\"\n",
    "    return observation.step % configuration.signs\n",
    "\n",
    "def losing_agent(observation, configuration):\n",
    "    \"\"\"Агент всегда выбирает действие, которое проигрывает предыдущему ходу противника\"\"\"\n",
    "    if observation.step > 0:\n",
    "        return (observation.lastOpponentAction - 1) % configuration.signs\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "def smart_random_agent(observation, configuration):\n",
    "    \"\"\"Агент с 70% вероятностью повторяет успешный ход, иначе выбирает случайно\"\"\"\n",
    "    if observation.step > 0 and random.random() < 0.7:\n",
    "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "def bias_rock_agent(observation, configuration):\n",
    "    \"\"\"Агент с 60% вероятностью выбирает Камень\"\"\"\n",
    "    return 0 if random.random() < 0.6 else random.randrange(1, configuration.signs)\n",
    "\n",
    "def bias_paper_agent(observation, configuration):\n",
    "    \"\"\"Агент с 60% вероятностью выбирает Бумагу\"\"\"\n",
    "    return 1 if random.random() < 0.6 else random.randrange(0, configuration.signs)\n",
    "\n",
    "def bias_scissors_agent(observation, configuration):\n",
    "    \"\"\"Агент с 60% вероятностью выбирает Ножницы\"\"\"\n",
    "    return 2 if random.random() < 0.6 else random.randrange(0, configuration.signs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fd0b1",
   "metadata": {},
   "source": [
    "## Запуск турнира между агентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea79fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты турнира:\n",
      "                     Rock Agent  Copy Opponent  Random Agent  Paper Agent  \\\n",
      "Rock Agent                  0.0            0.0             0        -99.0   \n",
      "Copy Opponent               0.0            0.0             0          0.0   \n",
      "Random Agent                0.0            0.0             0          0.0   \n",
      "Paper Agent                99.0            0.0             0          0.0   \n",
      "Scissors Agent            -99.0            0.0             0         99.0   \n",
      "Smart Agent                99.0           50.0             0         98.0   \n",
      "Cycle Agent                 0.0           98.0             0          0.0   \n",
      "Losing Agent              -97.0           99.0             0        -99.0   \n",
      "Smart Random Agent         63.0            0.0             0         65.0   \n",
      "Bias Rock Agent             0.0            0.0             0        -43.0   \n",
      "Bias Paper Agent           66.0            0.0             0          0.0   \n",
      "Bias Scissors Agent       -65.0            0.0             0         68.0   \n",
      "\n",
      "                     Scissors Agent  Smart Agent  Cycle Agent  Losing Agent  \\\n",
      "Rock Agent                     99.0        -98.0          0.0          98.0   \n",
      "Copy Opponent                   0.0         99.0        -98.0          50.0   \n",
      "Random Agent                    0.0          0.0          0.0           0.0   \n",
      "Paper Agent                   -99.0        -98.0          0.0          99.0   \n",
      "Scissors Agent                  0.0        -99.0          0.0          97.0   \n",
      "Smart Agent                    99.0          0.0          0.0          99.0   \n",
      "Cycle Agent                     0.0          0.0          0.0         -98.0   \n",
      "Losing Agent                  -97.0         50.0         98.0           0.0   \n",
      "Smart Random Agent             73.0          0.0          0.0           0.0   \n",
      "Bias Rock Agent                36.0        -26.0          0.0          20.0   \n",
      "Bias Paper Agent              -64.0        -37.0          0.0          42.0   \n",
      "Bias Scissors Agent             0.0        -31.0          0.0          24.0   \n",
      "\n",
      "                     Smart Random Agent  Bias Rock Agent  Bias Paper Agent  \\\n",
      "Rock Agent                        -58.0              0.0             -59.0   \n",
      "Copy Opponent                       0.0              0.0               0.0   \n",
      "Random Agent                        0.0              0.0               0.0   \n",
      "Paper Agent                       -65.0             33.0               0.0   \n",
      "Scissors Agent                    -74.0            -36.0              51.0   \n",
      "Smart Agent                         0.0              0.0              36.0   \n",
      "Cycle Agent                         0.0              0.0               0.0   \n",
      "Losing Agent                        0.0            -24.0             -26.0   \n",
      "Smart Random Agent                  0.0              0.0               0.0   \n",
      "Bias Rock Agent                     0.0              0.0               0.0   \n",
      "Bias Paper Agent                  -31.0             28.0               0.0   \n",
      "Bias Scissors Agent               -23.0            -29.0              45.0   \n",
      "\n",
      "                     Bias Scissors Agent  \n",
      "Rock Agent                          58.0  \n",
      "Copy Opponent                        0.0  \n",
      "Random Agent                         0.0  \n",
      "Paper Agent                        -64.0  \n",
      "Scissors Agent                       0.0  \n",
      "Smart Agent                         49.0  \n",
      "Cycle Agent                          0.0  \n",
      "Losing Agent                       -47.0  \n",
      "Smart Random Agent                  28.0  \n",
      "Bias Rock Agent                     21.0  \n",
      "Bias Paper Agent                   -36.0  \n",
      "Bias Scissors Agent                  0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Инициализация среды\n",
    "env = make(\"rps\", configuration={\"episodeSteps\": 100})\n",
    "\n",
    "# Список агентов\n",
    "agents = [\n",
    "    rock_agent, copy_opponent, random_agent, paper_agent, scissors_agent, smart_agent,\n",
    "    cycle_agent, losing_agent, smart_random_agent, bias_rock_agent,\n",
    "    bias_paper_agent, bias_scissors_agent\n",
    "]\n",
    "\n",
    "# Турнир\n",
    "results = []\n",
    "for i, agent1 in enumerate(agents):\n",
    "    row = []\n",
    "    for j, agent2 in enumerate(agents):\n",
    "        env.reset()\n",
    "        env.run([agent1, agent2])  # Запуск игры между двумя агентами\n",
    "        rewards = env.state\n",
    "        row.append(rewards[0]['reward'])  # Сохраняем результат для первого агента\n",
    "    results.append(row)\n",
    "\n",
    "# Форматирование результатов в таблицу\n",
    "columns = [\n",
    "    \"Rock Agent\", \"Copy Opponent\", \"Random Agent\", \"Paper Agent\", \n",
    "    \"Scissors Agent\", \"Smart Agent\", \"Cycle Agent\", \"Losing Agent\", \n",
    "    \"Smart Random Agent\", \"Bias Rock Agent\", \"Bias Paper Agent\", \n",
    "    \"Bias Scissors Agent\"\n",
    "]\n",
    "results_df = pd.DataFrame(results, columns=columns, index=columns)\n",
    "\n",
    "# Вывод таблицы\n",
    "print(\"Результаты турнира:\")\n",
    "print(results_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9127440-5182-406e-aef7-a3e120232921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
